\section{Derivation}

Let a continuous time linear \gls{system} be defined as

\begin{equation}
  \dot{\mtx{x}} = \mtx{A}\mtx{x} + \mtx{B}\mtx{u}
\end{equation}

with the cost function

\begin{equation*}
  J = \int\limits_0^\infty
    \begin{bmatrix}
      \mtx{x} \\
      \mtx{u}
    \end{bmatrix}^T
    \begin{bmatrix}
      \mtx{Q} & \mtx{N} \\
      \mtx{N}^T & \mtx{R}
    \end{bmatrix}
    \begin{bmatrix}
      \mtx{x} \\
      \mtx{u}
    \end{bmatrix} dt
\end{equation*}

where $J$ represents a trade-off between \gls{state} excursion and
\gls{control effort} with the weighting factors $\mtx{Q}$, $\mtx{R}$, and
$\mtx{N}$. $\mtx{Q}$ is the weight matrix for \gls{error}, $\mtx{R}$ is the
weight matrix for \gls{control effort}, and $\mtx{N}$ is a cross weight matrix
between \gls{error} and \gls{control effort}. $\mtx{N}$ is commonly utilized
when penalizing the output in addition to the state and input.

\begin{align*}
  J &= \int\limits_0^\infty
    \begin{bmatrix}
      \mtx{x} \\
      \mtx{u}
    \end{bmatrix}^T
    \begin{bmatrix}
      \mtx{Q}\mtx{x} + \mtx{N}\mtx{u} \\
      \mtx{N}^T\mtx{x} + \mtx{R}\mtx{u}
    \end{bmatrix} dt \\
  J &= \int\limits_0^\infty
    \begin{bmatrix}
      \mtx{x}^T & \mtx{u}^T
    \end{bmatrix}
    \begin{bmatrix}
      \mtx{Q}\mtx{x} + \mtx{N}\mtx{u} \\
      \mtx{N}^T\mtx{x} + \mtx{R}\mtx{u}
    \end{bmatrix} dt \\
  J &= \int\limits_0^\infty
    \left(\mtx{x}^T\left(\mtx{Q}\mtx{x} + \mtx{N}\mtx{u}\right) +
      \mtx{u}^T\left(\mtx{N}^T\mtx{x} + \mtx{R}\mtx{u}\right)\right) dt \\
  J &= \int\limits_0^\infty
    \left(\mtx{x}^T\mtx{Q}\mtx{x} + \mtx{x}^T\mtx{N}\mtx{u} +
      \mtx{u}^T\mtx{N}^T\mtx{x} + \mtx{u}^T\mtx{R}\mtx{u}\right) dt \\
  J &= \int\limits_0^\infty
    \left(\mtx{x}^T\mtx{Q}\mtx{x} + \mtx{x}^T\mtx{N}\mtx{u} +
      \left(\mtx{x}^T\mtx{N}\mtx{u}\right)^T + \mtx{u}^T\mtx{R}\mtx{u}\right)
    dt \\
  J &= \int\limits_0^\infty
    \left(\mtx{x}^T\mtx{Q}\mtx{x} + 2\mtx{x}^T\mtx{N}\mtx{u} +
      \mtx{u}^T\mtx{R}\mtx{u}\right) dt \\
  J &= \int\limits_0^\infty
    \left(\mtx{x}^T\mtx{Q}\mtx{x} + \mtx{u}^T\mtx{R}\mtx{u} +
      2\mtx{x}^T\mtx{N}\mtx{u}\right) dt
\end{align*}

The feedback \gls{control law} which minimizes $J$ subject to the constraint
$\dot{\mtx{x}} = \mtx{A}\mtx{x} + \mtx{B}\mtx{u}$ is

\begin{equation*}
  \mtx{u} = -\mtx{K}\mtx{x}
\end{equation*}

where $\mtx{K}$ is given by

\begin{equation*}
  \mtx{K} = \mtx{R}^{-1} \left(\mtx{B}^T\mtx{S} + \mtx{N}^T\right)
\end{equation*}

and $\mtx{S}$ is found by solving the continuous time algebraic Riccati equation
defined as

\begin{equation*}
  \mtx{A}^T\mtx{S} + \mtx{S}\mtx{A} - \left(\mtx{S}\mtx{B} +
    \mtx{N}\right) \mtx{R}^{-1} \left(\mtx{B}^T\mtx{S} + \mtx{N}^T\right) +
    \mtx{Q} = 0
\end{equation*}

or alternatively

\begin{equation*}
  \mathscrbf{A}^T\mtx{S} + \mtx{S}\mathscrbf{A} -
    \mtx{S}\mtx{B}\mtx{R}^{-1}\mtx{B}^T\mtx{S} + \mathscrbf{Q} = 0
\end{equation*}

with

\begin{align*}
  \mathscrbf{A} &= \mtx{A} - \mtx{B}\mtx{R}^{-1}\mtx{N}^T \\
  \mathscrbf{Q} &= \mtx{Q} - \mtx{N}\mtx{R}^{-1}\mtx{N}^T
\end{align*}

If there is no cross-correlation between \gls{error} and \gls{control effort},
$\mtx{N}$ is a zero matrix and the cost function simplifies to

\begin{equation*}
  J = \int\limits_0^\infty
    \left(\mtx{x}^T\mtx{Q}\mtx{x} + \mtx{u}^T\mtx{R}\mtx{u}\right) dt
\end{equation*}

The feedback \gls{control law} which minimizes this $J$ subject to
$\dot{\mtx{x}} = \mtx{A}\mtx{x} + \mtx{B}\mtx{u}$ is

\begin{equation*}
  \mtx{u} = -\mtx{K}\mtx{x}
\end{equation*}

where $\mtx{K}$ is given by

\begin{equation*}
  \mtx{K} = \mtx{R}^{-1}\mtx{B}^T\mtx{S}
\end{equation*}

and $\mtx{S}$ is found by solving the continuous time algebraic Riccati equation
defined as

\begin{equation*}
  \mtx{A}^T\mtx{S} + \mtx{S}\mtx{A} -
    \mtx{S}\mtx{B}\mtx{R}^{-1}\mtx{B}^T\mtx{S} + \mtx{Q} = 0
\end{equation*}

The discrete time LQR \gls{controller} is computed via a slightly different cost
function, constraint, and resulting algebraic Riccati equation. Snippet
\ref{lst:lqr} computes the optimal infinite horizon, discrete time LQR
\gls{controller}.

\begin{code}{Python}{build/frccontrol/frccontrol/lqr.py}
  \caption{Infinite horizon, discrete time LQR computation in Python}
  \label{lst:lqr}
\end{code}

Other formulations of LQR for finite horizon and discrete time can be seen on
Wikipedia \cite{bib:wiki_lqr}.

MIT OpenCourseWare has a rigorous proof of the results shown above
\cite{bib:lqr_derivs}.
