\section{Derivation}

Let a continuous time linear \gls{system} be defined as
\begin{equation}
  \dot{\mat{x}} = \mat{A}\mat{x} + \mat{B}\mat{u}
\end{equation}

with the cost function
\begin{equation*}
  J = \int\limits_0^\infty
    \begin{bmatrix}
      \mat{x} \\
      \mat{u}
    \end{bmatrix}\T
    \begin{bmatrix}
      \mat{Q} & \mat{N} \\
      \mat{N}\T & \mat{R}
    \end{bmatrix}
    \begin{bmatrix}
      \mat{x} \\
      \mat{u}
    \end{bmatrix} dt
\end{equation*}

where $J$ represents a trade-off between \gls{state} excursion and
\gls{control effort} with the weighting factors $\mat{Q}$, $\mat{R}$, and
$\mat{N}$. $\mat{Q}$ is the weight matrix for \gls{error}, $\mat{R}$ is the
weight matrix for \gls{control effort}, and $\mat{N}$ is a cross weight matrix
between \gls{error} and \gls{control effort}. $\mat{N}$ is commonly utilized
when penalizing the output in addition to the state and input.
\begin{align*}
  J &= \int\limits_0^\infty
    \begin{bmatrix}
      \mat{x} \\
      \mat{u}
    \end{bmatrix}\T
    \begin{bmatrix}
      \mat{Q}\mat{x} + \mat{N}\mat{u} \\
      \mat{N}\T\mat{x} + \mat{R}\mat{u}
    \end{bmatrix} dt \\
  J &= \int\limits_0^\infty
    \begin{bmatrix}
      \mat{x}\T & \mat{u}\T
    \end{bmatrix}
    \begin{bmatrix}
      \mat{Q}\mat{x} + \mat{N}\mat{u} \\
      \mat{N}\T\mat{x} + \mat{R}\mat{u}
    \end{bmatrix} dt \\
  J &= \int\limits_0^\infty
    \left(\mat{x}\T\left(\mat{Q}\mat{x} + \mat{N}\mat{u}\right) +
      \mat{u}\T\left(\mat{N}\T\mat{x} + \mat{R}\mat{u}\right)\right) dt \\
  J &= \int\limits_0^\infty
    \left(\mat{x}\T\mat{Q}\mat{x} + \mat{x}\T\mat{N}\mat{u} +
      \mat{u}\T\mat{N}\T\mat{x} + \mat{u}\T\mat{R}\mat{u}\right) dt \\
  J &= \int\limits_0^\infty
    \left(\mat{x}\T\mat{Q}\mat{x} + \mat{x}\T\mat{N}\mat{u} +
      \left(\mat{x}\T\mat{N}\mat{u}\right)\T + \mat{u}\T\mat{R}\mat{u}\right)
    dt \\
  J &= \int\limits_0^\infty
    \left(\mat{x}\T\mat{Q}\mat{x} + 2\mat{x}\T\mat{N}\mat{u} +
      \mat{u}\T\mat{R}\mat{u}\right) dt \\
  J &= \int\limits_0^\infty
    \left(\mat{x}\T\mat{Q}\mat{x} + \mat{u}\T\mat{R}\mat{u} +
      2\mat{x}\T\mat{N}\mat{u}\right) dt
\end{align*}

The feedback \gls{control law} which minimizes $J$ subject to the constraint
$\dot{\mat{x}} = \mat{A}\mat{x} + \mat{B}\mat{u}$ is
\begin{equation*}
  \mat{u} = -\mat{K}\mat{x}
\end{equation*}

where $\mat{K}$ is given by
\begin{equation*}
  \mat{K} = \mat{R}^{-1} \left(\mat{B}\T\mat{S} + \mat{N}\T\right)
\end{equation*}

and $\mat{S}$ is found by solving the continuous time algebraic Riccati equation
defined as
\begin{equation*}
  \mat{A}\T\mat{S} + \mat{S}\mat{A} - \left(\mat{S}\mat{B} +
    \mat{N}\right) \mat{R}^{-1} \left(\mat{B}\T\mat{S} + \mat{N}\T\right) +
    \mat{Q} = 0
\end{equation*}

or alternatively
\begin{equation*}
  \mathcal{A}\T\mat{S} + \mat{S}\mathcal{A} -
    \mat{S}\mat{B}\mat{R}^{-1}\mat{B}\T\mat{S} + \mathcal{Q} = 0
\end{equation*}

with
\begin{align*}
  \mathcal{A} &= \mat{A} - \mat{B}\mat{R}^{-1}\mat{N}\T \\
  \mathcal{Q} &= \mat{Q} - \mat{N}\mat{R}^{-1}\mat{N}\T
\end{align*}

If there is no cross-correlation between \gls{error} and \gls{control effort},
$\mat{N}$ is a zero matrix and the cost function simplifies to
\begin{equation*}
  J = \int\limits_0^\infty
    \left(\mat{x}\T\mat{Q}\mat{x} + \mat{u}\T\mat{R}\mat{u}\right) dt
\end{equation*}

The feedback \gls{control law} which minimizes this $J$ subject to
$\dot{\mat{x}} = \mat{A}\mat{x} + \mat{B}\mat{u}$ is
\begin{equation*}
  \mat{u} = -\mat{K}\mat{x}
\end{equation*}

where $\mat{K}$ is given by
\begin{equation*}
  \mat{K} = \mat{R}^{-1}\mat{B}\T\mat{S}
\end{equation*}

and $\mat{S}$ is found by solving the continuous time algebraic Riccati equation
defined as
\begin{equation*}
  \mat{A}\T\mat{S} + \mat{S}\mat{A} -
    \mat{S}\mat{B}\mat{R}^{-1}\mat{B}\T\mat{S} + \mat{Q} = 0
\end{equation*}

The discrete time LQR \gls{controller} is computed via a slightly different cost
function, constraint, and resulting algebraic Riccati equation. Snippet
\ref{lst:lqr} computes the optimal infinite horizon, discrete time LQR
\gls{controller}.
\begin{code}{Python}{build/frccontrol/frccontrol/lqr.py}
  \caption{Infinite horizon, discrete time LQR computation in Python}
  \label{lst:lqr}
\end{code}

Other formulations of LQR for finite horizon and discrete time can be seen on
Wikipedia \cite{bib:wiki_lqr}.

MIT OpenCourseWare has a rigorous proof of the results shown above
\cite{bib:lqr_derivs}.
