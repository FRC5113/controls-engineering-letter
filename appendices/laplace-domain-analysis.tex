\chapterimage{appendices.jpg}{Sunset in an airplane over New Mexico}

\chapter{Laplace domain analysis}

This appendix uses Laplace transforms and transfer functions to analyze
properties of control systems like \gls{steady-state error}.

These case studies cover various aspects of PID control using the algebraic
approach of transfer functions. For this, we'll be using equation
(\ref{eq:pid_tf}), the transfer function for a PID controller.

\begin{equation}
  K(s) = K_p + \frac{K_i}{s} + K_ds \label{eq:pid_tf}
\end{equation}

\section{Laplace transform definition}

The Laplace transform of a function $f(t)$ is defined as

\begin{equation*}
  \mathcal{L}\{f(t)\} = F(s) = \int_0^\infty f(t) e^{-st} \,dt
\end{equation*}

We won't be computing any Laplace transforms by hand using this formula
(everyone in the real world looks these up in a table anyway). Common Laplace
transforms (assuming zero initial conditions) are shown in table
\ref{tab:common_laplace_transforms}. Of particular note are the Laplace
transforms for the derivative, unit step\footnote{The unit step $u(t)$ is
defined as $0$ for $t < 0$ and $1$ for $t \ge 0$.}, and exponential decay. We
can see that a derivative is equivalent to multiplying by $s$, and an integral
is equivalent to multiplying by $\frac{1}{s}$.

\begin{booktable}
  \begin{tabular}{|ccc|}
    \hline
    \rowcolor{headingbg}
    & \textbf{Time domain} & \textbf{Laplace domain} \\
    \hline
    Linearity & $a\,f(t) + b\,g(t)$ & $a\,F(s) + b\,G(s)$ \\
    Convolution & $(f * g)(t)$ & $F(s) \,G(s)$ \\
    Derivative & $f'(t)$ & $s \,F(s)$ \\
    $n^{th}$ derivative & $f^{(n)}(t)$ & $s^n \,F(s)$ \\
    Unit step & $u(t)$ & $\frac{1}{s}$ \\
    Ramp & $t \,u(t)$ & $\frac{1}{s^2}$ \\
    Exponential decay & $e^{-\alpha t} u(t)$ & $\frac{1}{s + \alpha}$ \\
    \hline
  \end{tabular}
  \caption{Common Laplace transforms and Laplace transform properties with zero
    initial conditions}
  \label{tab:common_laplace_transforms}
\end{booktable}

\section{Case study: steady-state error}
\index{Steady-state error}

To demonstrate the problem of \gls{steady-state error}, we will use a DC brushed
motor controlled by a velocity PID controller. A DC brushed motor has a transfer
function from voltage ($V$) to angular velocity ($\dot{\theta}$) of

\begin{equation}
  G(s) = \frac{\dot{\Theta}(s)}{V(s)} = \frac{K}{(Js+b)(Ls+R)+K^2}
\end{equation}

First, we'll try controlling it with a P controller defined as

\begin{equation*}
  K(s) = K_p
\end{equation*}

When these are in unity feedback, the transfer function from the input voltage
to the error is

\begin{align*}
  \frac{E(s)}{V(s)} &= \frac{1}{1 + K(s)G(s)} \\
  E(s) &= \frac{1}{1 + K(s)G(s)} V(s) \\
  E(s) &= \frac{1}{1 + (K_p) \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} V(s) \\
  E(s) &= \frac{1}{1 + \frac{K_p K}{(Js+b)(Ls+R)+K^2}} V(s)
\end{align*}

The steady-state of a transfer function can be found via

\begin{equation}
  \lim_{s\to0} sH(s)
\end{equation}

since steady-state has an input frequency of zero.

\begin{align}
  e_{ss} &= \lim_{s\to0} sE(s) \nonumber \\
  e_{ss} &= \lim_{s\to0} s \frac{1}{1 + \frac{K_p K}{(Js+b)(Ls+R)+K^2}} V(s)
    \nonumber \\
  e_{ss} &= \lim_{s\to0} s \frac{1}{1 + \frac{K_p K}{(Js+b)(Ls+R)+K^2}}
    \frac{1}{s} \nonumber \\
  e_{ss} &= \lim_{s\to0} \frac{1}{1 + \frac{K_p K}{(Js+b)(Ls+R)+K^2}}
    \nonumber \\
  e_{ss} &= \frac{1}{1 + \frac{K_p K}{(J(0)+b)(L(0)+R)+K^2}} \nonumber \\
  e_{ss} &= \frac{1}{1 + \frac{K_p K}{bR+K^2}} \label{eq:ss_nonzero}
\end{align}

Notice that the \gls{steady-state error} is nonzero. To fix this, an integrator
must be included in the controller.

\begin{equation*}
  K(s) = K_p + \frac{K_i}{s}
\end{equation*}

The same steady-state calculations are performed as before with the new
controller.

\begin{align*}
  \frac{E(s)}{V(s)} &= \frac{1}{1 + K(s)G(s)} \\
  E(s) &= \frac{1}{1 + K(s)G(s)} V(s) \\
  E(s) &= \frac{1}{1 + \left(K_p + \frac{K_i}{s}\right)
    \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} \left(\frac{1}{s}\right) \\
  e_{ss} &= \lim_{s\to0} s \frac{1}{1 + \left(K_p + \frac{K_i}{s}\right)
    \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} \left(\frac{1}{s}\right) \\
  e_{ss} &= \lim_{s\to0} \frac{1}{1 + \left(K_p + \frac{K_i}{s}\right)
    \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} \\
  e_{ss} &= \lim_{s\to0} \frac{1}{1 + \left(K_p + \frac{K_i}{s}\right)
    \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} \frac{s}{s} \\
  e_{ss} &= \lim_{s\to0} \frac{s}{s + \left(K_p s + K_i\right)
    \left(\frac{K}{(Js+b)(Ls+R)+K^2}\right)} \\
  e_{ss} &= \frac{0}{0 + (K_p (0) + K_i)
    \left(\frac{K}{(J(0)+b)(L(0)+R)+K^2}\right)} \\
  e_{ss} &= \frac{0}{K_i \frac{K}{bR+K^2}}
\end{align*}

The denominator is nonzero, so $e_{ss} = 0$. Therefore, an integrator is
required to eliminate \gls{steady-state error} in all cases for this
\gls{model}.

It should be noted that $e_{ss}$ in equation (\ref{eq:ss_nonzero}) approaches
zero for $K_p = \infty$. This is known as a bang-bang controller. In practice,
an infinite switching frequency cannot be achieved, but it may be close enough
for some performance specifications.

\section{Case study: flywheel PID control}
\label{subsec:case_study:_flywheel_pid_control}
\index{PID control}

PID controllers typically control voltage to a motor in FRC independent of the
equations of motion of that motor. For position PID control, large values of
$K_p$ can lead to overshoot and $K_d$ is commonly used to reduce overshoots.
Let's consider a flywheel controlled with a standard PID controller. Why
wouldn't $K_d$ provide damping for velocity overshoots in this case?

PID control is designed to control second-order and first-order \glspl{system}
well. It can be used to control a lot of things, but struggles when given higher
order \glspl{system}. It has three degrees of freedom. Two are used to place the
two poles of the \gls{system}, and the third is used to remove steady-state
error. With higher order \glspl{system} like a one input, seven \gls{state}
\gls{system}, there aren't enough degrees of freedom to place the \gls{system}'s
poles in desired locations. This will result in poor control.

The math for PID doesn't assume voltage, a motor, etc. It defines an output
based on derivatives and integrals of its input. We happen to use it for motors
because it actually works pretty well for it because motors are second-order
\glspl{system}.

The following math will be in continuous time, but the same ideas apply to
discrete time. This is all assuming a velocity controller.

Our simple motor model hooked up to a mass is

\begin{align}
  V &= IR + \frac{\omega}{K_v} \label{eq:cs_flywheel_1} \\
  \tau &= I K_t \label{eq:cs_flywheel_2} \\
  \tau &= J \frac{d\omega}{dt} \label{eq:cs_flywheel_3}
\end{align}

For an explanation of where these equations come from, read section
\ref{sec:dc_brushed_motor}.

First, we'll solve for $\frac{d\omega}{dt}$ in terms of $V$.

Substitute equation (\ref{eq:cs_flywheel_2}) into equation
(\ref{eq:cs_flywheel_1}).

\begin{align*}
  V &= IR + \frac{\omega}{K_v} \\
  V &= \left(\frac{\tau}{K_t}\right) R + \frac{\omega}{K_v}
\end{align*}

Substitute in equation (\ref{eq:cs_flywheel_3}).

\begin{align*}
  V &= \frac{\left(J \frac{d\omega}{dt}\right)}{K_t} R + \frac{\omega}{K_v} \\
\end{align*}

Solve for $\frac{d\omega}{dt}$.

\begin{align*}
  V &= \frac{J \frac{d\omega}{dt}}{K_t} R + \frac{\omega}{K_v} \\
  V - \frac{\omega}{K_v} &= \frac{J \frac{d\omega}{dt}}{K_t} R \\
  \frac{d\omega}{dt} &= \frac{K_t}{JR} \left(V - \frac{\omega}{K_v}\right) \\
  \frac{d\omega}{dt} &= -\frac{K_t}{JRK_v} \omega + \frac{K_t}{JR} V
\end{align*}

Now take the Laplace transform. Because the Laplace transform is a linear
operator, we can take the Laplace transform of each term individually. Based on
table \ref{tab:common_laplace_transforms}, $\frac{d\omega}{dt}$ becomes
$s\omega$ and $\omega(t)$ and $V(t)$ become $\omega(s)$ and $V(s)$ respectively
(the parenthetical notation has been dropped for clarity).

\begin{equation}
  s \omega = -\frac{K_t}{JRK_v} \omega + \frac{K_t}{JR} V
  \label{eq:cs_motor_tf}
\end{equation}

Solve for the transfer function $H(s) = \frac{\omega}{V}$.

\begin{align*}
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t}{JR} V \\
  \left(s + \frac{K_t}{JRK_v}\right) \omega &= \frac{K_t}{JR} V \\
  \frac{\omega}{V} &= \frac{\frac{K_t}{JR}}{s + \frac{K_t}{JRK_v}} \\
\end{align*}

That gives us a pole at $-\frac{K_t}{JRK_v}$, which is actually stable. Notice
that there is only one pole.

First, we'll use a simple P loop.

\begin{equation*}
  V = K_p (\omega_{goal} - \omega)
\end{equation*}

Substitute this controller into equation (\ref{eq:cs_motor_tf}).

\begin{equation*}
  s \omega = -\frac{K_t}{JRK_v} \omega + \frac{K_t}{JR} K_p (\omega_{goal} -
    \omega)
\end{equation*}

Solve for the transfer function $H(s) = \frac{\omega}{\omega_{goal}}$.

\begin{align*}
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t K_p}{JR} (\omega_{goal} -
    \omega) \\
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t K_p}{JR} \omega_{goal} -
    \frac{K_t K_p}{JR} \omega \\
  \left(s + \frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}\right) \omega &=
    \frac{K_t K_p}{JR} \omega_{goal} \\
  \frac{\omega}{\omega_{goal}} &= \frac{\frac{K_t K_p}{JR}}
    {\left(s + \frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}\right)} \\
\end{align*}

This has a pole at $-\left(\frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}\right)$.
Assuming that that quantity is negative (i.e., we are stable), that pole
corresponds to a time constant of
$\frac{1}{\frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}}$.

As can be seen above, a flywheel has a single pole. It therefore only needs a
single pole controller to place all of its poles anywhere.

\begin{remark}
  This analysis assumes that the motor is well coupled to the mass and that the
  time constant of the inductor is small enough that it doesn't factor into the
  motor equations. In Austin Schuh's experience with 971's robots, these are
  pretty good assumptions.
\end{remark}

Next, we'll try a PD loop. (This will use a perfect derivative, but anyone
following along closely already knows that we can't really take a derivative
here, so the math will need to be updated at some point. We could switch to
discrete time and pick a differentiation method, or pick some other way of
modeling the derivative.)

\begin{equation*}
  V = K_p (\omega_{goal} - \omega) + K_d s (\omega_{goal} - \omega)
\end{equation*}

Substitute this controller into equation (\ref{eq:cs_motor_tf}).

\begin{align*}
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t}{JR}
    \left(K_p (\omega_{goal} - \omega) + K_d s (\omega_{goal} - \omega)\right)
    \\
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t K_p}{JR}
    (\omega_{goal} - \omega) + \frac{K_t K_d s}{JR} (\omega_{goal} - \omega) \\
  s \omega &= -\frac{K_t}{JRK_v} \omega + \frac{K_t K_p}{JR} \omega_{goal} -
    \frac{K_t K_p}{JR} \omega + \frac{K_t K_d s}{JR} \omega_{goal} -
    \frac{K_t K_d s}{JR} \omega \\
\end{align*}

Collect the common terms on separate sides and refactor.

\begin{align*}
  s \omega + \frac{K_t K_d s}{JR} \omega + \frac{K_t}{JRK_v} \omega +
    \frac{K_t K_p}{JR} \omega &= \frac{K_t K_p}{JR} \omega_{goal} +
    \frac{K_t K_d s}{JR} \omega_{goal} \\
  \left(s \left(1 + \frac{K_t K_d}{JR}\right) + \frac{K_t}{JRK_v} +
    \frac{K_t K_p}{JR}\right) \omega &= \frac{K_t}{JR}
    \left(K_p + K_d s\right) \omega_{goal} \\
  \frac{\omega}{\omega_{goal}} &= \frac{\frac{K_t}{JR}
    \left(K_p + K_d s\right)}{\left(s \left(1 + \frac{K_t K_d}{JR}\right) +
    \frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}\right)} \\
\end{align*}

So, we added a zero at $-\frac{K_p}{K_d}$ and moved our pole to
$-\frac{\frac{K_t}{JRK_v} + \frac{K_t K_p}{JR}}{1 + \frac{K_t K_d}{JR}}$. This
isn't progress. We've added more complexity to our \gls{system} and, practically
speaking, gotten nothing good in return. Zeroes should be avoided if at all
possible because they amplify unwanted high frequency modes of the \gls{system}
and are noisier the faster the \gls{system} is sampled. At least this is a stable
zero, but it's still undesirable.

In summary, derivative doesn't help on an ideal flywheel. $K_d$ may compensate
for unmodeled dynamics such as accelerating projectiles slowing the flywheel
down, but that effect may also increase recovery time; $K_d$ drives the
acceleration to zero in the undesired case of negative acceleration as well as
well as the actually desired case of positive acceleration.

We'll cover a superior compensation method much later in subsection
\ref{subsec:u_error_estimation} that avoids zeroes in the \gls{controller},
doesn't act against the desired control action, and facilitates better
\gls{tracking}.
