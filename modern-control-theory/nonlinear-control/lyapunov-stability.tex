\section{Lyapunov stability}
\index{nonlinear control!Lyapunov stability}

Lyapunov stability is a fundamental concept in nonlinear control, so we're going
to give a brief overview of what it is so students can research it further.

Since the \gls{state} evolution in nonlinear \glspl{system} is defined by a
function rather than a constant matrix, the \gls{system}'s poles as determined
by \gls{linearization} move around. Nonlinear control uses Lyapunov stability to
determine if nonlinear \glspl{system} are stable. From a linear control theory
point of view, Lyapunov stability says the \gls{system} is stable if, for a
given initial condition, all possible eigenvalues of $\mat{A}$ from that point
on remain in the left-half plane. However, nonlinear control uses a different
definition.

Lyapunov stability means that the \gls{system} trajectory can be kept
arbitrarily close to the origin by starting sufficiently close to it. Lyapunov's
direct method uses a function consisting of the energy in a \gls{system} or
derivatives of the \gls{system}'s \gls{state} to prove stability around an
equilibrium point. This is done by showing that the function, and thus its
inputs, decay to some ground state.

More than one Lyapunov function can prove stability, and if one function doesn't
prove it, another candidate should be tried. For this reason, we refer to these
functions as \textit{Lyapunov candidate functions}.
