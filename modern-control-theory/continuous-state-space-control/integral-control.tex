\section{Integral control}
\label{sec:integral_control}

A common way of implementing integral control is to add an additional
\gls{state} that is the integral of the \gls{error} of the variable intended to
have zero \gls{steady-state error}.

We'll present two methods:
\begin{enumerate}
  \item Augment the \gls{plant}. For an arm, one would add an ``integral of
    position" state.
  \item Estimate the ``error" in the \gls{control input} (the difference between
    what was applied versus what was observed to happen) via the \gls{observer}
    and compensate for it. We'll call this ``input error estimation".
\end{enumerate}

In FRC, avoid integral control unless you have a very good reason to use it.
Integral control adds significant complexity, and steady-state error can often
be avoided with a motion profile, a well-tuned feedforward, and proportional
feedback (i.e., more deterministic options you should be using anyway).

\subsection{Plant augmentation}
\index{integral control!plant augmentation}

\subsubsection{Caveats}

First, unconstrained integral control exhibits integral windup on a unit
\gls{step input}. When the error reaches zero, the integrator may still have a
large positive accumulated error from the initial ramp-up. The integrator makes
the system overshoot until the accumulated error is unwound by negative errors.
Poor tuning can lead to instability.\footnote{With proper tuning, proportional
control should generally be doing much more work than integral control.}
Integrating only when close to the \gls{reference} somewhat mitigates integral
windup.

Second, unconstrained integral control is a poor choice for modeled dynamics
compensation. Feedforwards provide more precise compensation since we already
know beforehand how to counteract the undesirable dynamics.

Third, unconstrained integral control is a poor choice for unmodeled dynamics
compensation. To choose proper gains, the integrator must be tuned online when
the unmodeled dynamics are present, which may be inconvenient or unsafe in some
circumstances. Furthermore, accumulation even when the system is following the
model means it still compensates for modeled dynamics despite our intent
otherwise. Prefer the approach in subsection
\ref{subsec:input_error_estimation}.

\subsubsection{Implementation}

We want to augment the \gls{system} with an integral term that integrates the
\gls{error} $\mat{e} = \mat{r} - \mat{y} = \mat{r} - \mat{C}\mat{x}$.
\begin{align*}
  \mat{x}_I &= \int \mat{e} \,dt \\
  \dot{\mat{x}}_I &= \mat{e} = \mat{r} - \mat{C}\mat{x}
\end{align*}

The \gls{plant} is augmented as
\begin{align*}
  \dot{\begin{bmatrix}
    \mat{x} \\
    \mat{x}_I
  \end{bmatrix}} &=
  \begin{bmatrix}
    \mat{A} & \mat{0} \\
    -\mat{C} & \mat{0}
  \end{bmatrix}
  \begin{bmatrix}
    \mat{x} \\
    \mat{x}_I
  \end{bmatrix} +
  \begin{bmatrix}
    \mat{B} \\
    \mat{0}
  \end{bmatrix}
  \mat{u} +
  \begin{bmatrix}
    \mat{0} \\
    \mat{I}
  \end{bmatrix}
  \mat{r} \\
  \dot{\begin{bmatrix}
    \mat{x} \\
    \mat{x}_I
  \end{bmatrix}} &=
  \begin{bmatrix}
    \mat{A} & \mat{0} \\
    -\mat{C} & \mat{0}
  \end{bmatrix}
  \begin{bmatrix}
    \mat{x} \\
    \mat{x}_I
  \end{bmatrix} +
  \begin{bmatrix}
    \mat{B} & \mat{0} \\
    \mat{0} & \mat{I}
  \end{bmatrix}
  \begin{bmatrix}
    \mat{u} \\
    \mat{r}
  \end{bmatrix}
\end{align*}

The controller is augmented as
\begin{align*}
  \mat{u} &= \mat{K} (\mat{r} - \mat{x}) - \mat{K}_I\mat{x}_I \\
  \mat{u} &=
  \begin{bmatrix}
    \mat{K} & \mat{K}_I
  \end{bmatrix}
  \left(\begin{bmatrix}
    \mat{r} \\
    \mat{0}
  \end{bmatrix} -
  \begin{bmatrix}
    \mat{x} \\
    \mat{x}_I
  \end{bmatrix}\right)
\end{align*}

\subsection{Input error estimation}
\label{subsec:input_error_estimation}
\index{integral control!input error estimation}

\Glspl{model} can predict \gls{system} behavior, but unmodeled
\glspl{disturbance} make the observed system behavior deviate from the model. We
want to react to these disturbances quickly and improve the model's predictive
power in the face of these disturbances.

Input error estimation uses a state observer (covered in chapter
\ref{ch:stochastic_control_theory}) to estimate the difference between the
provided model \gls{input} and a hypothetical input that makes the model match
the observed behavior. Subtracting this value from the provided input
compensates for unmodeled disturbances, and adding it to the state observer's
input makes the model better predict the system's future behavior.

First, we'll consider the one-dimensional case. Let $u_{error}$ be the
difference between the hypothetical \gls{input} with disturbances and the
provided \gls{input}. The $u_{error}$ term is then added to the \gls{system} as
follows.
\begin{align*}
  \dot{x} &= Ax + B\left(u + u_{error}\right)
  \intertext{$u + u_{error}$ is the hypothetical \gls{input} actually applied to
    the \gls{system}.}
  \dot{x} &= Ax + Bu + Bu_{error}
  \intertext{The following equation generalizes this to a multiple-input
    \gls{system}.}
  \dot{\mat{x}} &= \mat{A}\mat{x} + \mat{B}\mat{u} + \mat{B}_{error}u_{error}
\end{align*}

where $\mat{B}_{error}$ is a column vector that maps $u_{error}$ to changes in
the rest of the \gls{state} the same way $\mat{B}$ does for $\mat{u}$.
$\mat{B}_{error}$ is only a column of $\mat{B}$ if $u_{error}$ corresponds to an
existing \gls{input} within $\mat{u}$.

Given the above equation, we'll augment the \gls{plant} as
\begin{align*}
  \dot{\begin{bmatrix}
    \mat{x} \\
    u_{error}
  \end{bmatrix}} &=
  \begin{bmatrix}
    \mat{A} & \mat{B}_{error} \\
    \mat{0} & \mat{0}
  \end{bmatrix}
  \begin{bmatrix}
    \mat{x} \\
    u_{error}
  \end{bmatrix} +
  \begin{bmatrix}
    \mat{B} \\
    \mat{0}
  \end{bmatrix}
  \mat{u} \\
  \mat{y} &= \begin{bmatrix}
    \mat{C} & 0
  \end{bmatrix} \begin{bmatrix}
    \mat{x} \\
    u_{error}
  \end{bmatrix} + \mat{D}\mat{u}
\end{align*}

Notice how the \gls{state} is augmented with $u_{error}$. With this \gls{model},
the \gls{observer} will estimate both the \gls{state} and the $u_{error}$ term.
The controller is augmented similarly. $\mat{r}$ is augmented with a zero for
the goal $u_{error}$ term.
\begin{align*}
  \mat{u} &= \mat{K} \left(\mat{r} - \mat{x}\right) - \mat{k}_{error}u_{error}
    \\
  \mat{u} &=
  \begin{bmatrix}
    \mat{K} & \mat{k}_{error}
  \end{bmatrix}
  \left(\begin{bmatrix}
    \mat{r} \\
    0
  \end{bmatrix} -
  \begin{bmatrix}
    \mat{x} \\
    u_{error}
  \end{bmatrix}\right)
\end{align*}

where $\mat{k}_{error}$ is a column vector with a $1$ in a given row if
$u_{error}$ should be applied to that \gls{input} or a $0$ otherwise.

This process can be repeated for an arbitrary \gls{error} which can be corrected
via some linear combination of the \glspl{input}.
