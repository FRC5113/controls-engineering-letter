\section{State observers}

State \glspl{observer} are used to estimate \glspl{state} which cannot be
measured directly. This can be due to noisy measurements or the \gls{state} not
being measurable (a hidden \gls{state}). This information can be used for
\gls{localization}, which is the process of using external measurements to
determine an \gls{agent}'s pose\footnote{An agent is a system-agnostic term for
independent controlled actors like robots or aircraft.}, or orientation in the
world.

One type of \gls{state} estimator is LQE. ``LQE" stands for ``Linear-Quadratic
Estimator". Similar to LQR, it places the estimator poles such that it minimizes
the sum of squares of the estimation \gls{error}. The Luenberger \gls{observer}
and Kalman filter are examples of these, where the latter chooses the pole
locations optimally based on the \gls{model} and measurement uncertainties.

Computer vision can also be used for \gls{localization}. By extracting features
from an image taken by the \gls{agent}'s camera, like a retroreflective target
in FRC, and comparing them to known dimensions, one can determine where the
\gls{agent}'s camera would have to be to see that image. This can be used to
correct our \gls{state} estimate in the same way we do with an encoder or
gyroscope.

\subsection{Luenberger observer}
\index{State-space observers!Luenberger observer}

We'll introduce the Luenberger observer first to demonstrate the general form of
a state estimator and some of their properties.

\begin{theorem}[Luenberger observer]
  \begin{align}
    \dot{\hat{\mtx{x}}} &= \mtx{A}\hat{\mtx{x}} + \mtx{B}\mtx{u} +
      \mtx{L} (\mtx{y} - \hat{\mtx{y}}) \\
    \hat{\mtx{y}} &= \mtx{C}\hat{\mtx{x}} + \mtx{D}\mtx{u}
  \end{align}

  \begin{align}
    \hat{\mtx{x}}_{k+1} &= \mtx{A}\hat{\mtx{x}}_k + \mtx{B}\mtx{u}_k +
      \mtx{L}(\mtx{y}_k - \hat{\mtx{y}}_k) \label{eq:z_obsv_x} \\
    \hat{\mtx{y}}_k &= \mtx{C}\hat{\mtx{x}}_k + \mtx{D}\mtx{u}_k
      \label{eq:z_obsv_y} \\ \nonumber
  \end{align}

  \begin{figurekey}
    \begin{tabular}{llll}
      $\mtx{A}$ & system matrix      & $\hat{\mtx{x}}$ & state estimate vector \\
      $\mtx{B}$ & input matrix       & $\mtx{u}$ & input vector \\
      $\mtx{C}$ & output matrix      & $\mtx{y}$ & output vector \\
      $\mtx{D}$ & feedthrough matrix & $\hat{\mtx{y}}$ & output estimate vector \\
      $\mtx{L}$ & estimator gain matrix & & \\
    \end{tabular}
  \end{figurekey}
\end{theorem}

\begin{booktable}
  \begin{tabular}{|ll|ll|}
    \hline
    \rowcolor{headingbg}
    \textbf{Matrix} & \textbf{Rows $\times$ Columns} &
    \textbf{Matrix} & \textbf{Rows $\times$ Columns} \\
    \hline
    $\mtx{A}$ & states $\times$ states & $\hat{\mtx{x}}$ & states $\times$ 1 \\
    $\mtx{B}$ & states $\times$ inputs & $\mtx{u}$ & inputs $\times$ 1 \\
    $\mtx{C}$ & outputs $\times$ states & $\mtx{y}$ & outputs $\times$ 1 \\
    $\mtx{D}$ & outputs $\times$ inputs & $\hat{\mtx{y}}$ & outputs $\times$ 1 \\
    $\mtx{L}$ & states $\times$ outputs & & \\
    \hline
  \end{tabular}
  \caption{Luenberger observer matrix dimensions}
\end{booktable}

Variables denoted with a hat are estimates of the corresponding variable. For
example, $\hat{\mtx{x}}$ is the estimate of the true \gls{state} $\mtx{x}$.

Notice that a Luenberger \gls{observer} has an extra term in the \gls{state}
evolution equation. This term uses the difference between the estimated
\glspl{output} and measured \glspl{output} to steer the estimated \gls{state}
toward the true \gls{state}. Large values of $\mtx{L}$ trust the measurements
more while small values trust the \gls{model} more.

\begin{remark}
  Using an estimator forfeits the performance guarantees from earlier, but the
  responses are still generally very good if the process and measurement noises
  are small enough. See John Doyle's paper \textit{Guaranteed Margins for LQG
  Regulators} for a proof.
\end{remark}

A Luenberger \gls{observer} combines the prediction and update steps of an
estimator. To run them separately, use the equations in theorem
\ref{thm:luenberger} instead.

\begin{theorem}[Luenberger observer with separate predict/update]
  \label{thm:luenberger}

  \begin{align}
    \text{Predict step} \nonumber \\
    \hat{\mtx{x}}_{k+1}^- &= \mtx{A}\hat{\mtx{x}}_k^- + \mtx{B}\mtx{u}_k \\
    \text{Update step} \nonumber \\
    \hat{\mtx{x}}_{k+1}^+ &= \hat{\mtx{x}}_{k+1}^- + \mtx{A}^{-1}\mtx{L}
      (\mtx{y}_k - \hat{\mtx{y}}_k) \\
    \hat{\mtx{y}}_k &= \mtx{C} \hat{\mtx{x}}_k^-
  \end{align}
\end{theorem}

See appendix \ref{subsec:deriv_luenberger_separate} for a derivation.

\subsubsection{Eigenvalues of closed-loop observer}
\index{Stability!eigenvalues}

The eigenvalues of the system matrix can be used to determine whether a
\gls{state} \gls{observer}'s estimate will converge to the true \gls{state}.

Plugging equation \eqref{eq:z_obsv_y} into equation \eqref{eq:z_obsv_x} gives

\begin{align*}
  \hat{\mtx{x}}_{k+1} &= \mtx{A}\hat{\mtx{x}}_k + \mtx{B}\mtx{u}_k +
    \mtx{L} (\mtx{y}_k - \hat{\mtx{y}}_k) \\
  \hat{\mtx{x}}_{k+1} &= \mtx{A}\hat{\mtx{x}}_k + \mtx{B}\mtx{u}_k +
    \mtx{L} (\mtx{y}_k - (\mtx{C}\hat{\mtx{x}}_k + \mtx{D}\mtx{u}_k)) \\
  \hat{\mtx{x}}_{k+1} &= \mtx{A}\hat{\mtx{x}}_k + \mtx{B}\mtx{u}_k +
    \mtx{L} (\mtx{y}_k - \mtx{C}\hat{\mtx{x}}_k - \mtx{D}\mtx{u}_k)
\end{align*}

Plugging in equation \eqref{eq:ssz_ctrl_y} gives

\begin{align*}
  \hat{\mtx{x}}_{k+1} &= \mtx{A}\hat{\mtx{x}}_k + \mtx{B}\mtx{u}_k +
    \mtx{L}((\mtx{C}\mtx{x}_k + \mtx{D}\mtx{u}_k) - \mtx{C}\hat{\mtx{x}}_k -
    \mtx{D}\mtx{u}_k) \\
  \hat{\mtx{x}}_{k+1} &= \mtx{A}\hat{\mtx{x}}_k + \mtx{B}\mtx{u}_k +
    \mtx{L}(\mtx{C}\mtx{x}_k + \mtx{D}\mtx{u}_k - \mtx{C}\hat{\mtx{x}}_k -
    \mtx{D}\mtx{u}_k) \\
  \hat{\mtx{x}}_{k+1} &= \mtx{A}\hat{\mtx{x}}_k + \mtx{B}\mtx{u}_k +
    \mtx{L}(\mtx{C}\mtx{x}_k - \mtx{C}\hat{\mtx{x}}_k) \\
  \hat{\mtx{x}}_{k+1} &= \mtx{A}\hat{\mtx{x}}_k + \mtx{B}\mtx{u}_k +
    \mtx{L}\mtx{C}(\mtx{x}_k - \hat{\mtx{x}}_k)
\end{align*}

Let $E_k = \mtx{x}_k - \hat{\mtx{x}}_k$ be the \gls{error} in the estimate
$\hat{\mtx{x}}_k$.

\begin{equation*}
  \hat{\mtx{x}}_{k+1} = \mtx{A}\hat{\mtx{x}}_k + \mtx{B}\mtx{u}_k +
    \mtx{L}\mtx{C}\mtx{E}_k
\end{equation*}

Subtracting this from equation \eqref{eq:ssz_ctrl_x} gives

\begin{align}
  \mtx{x}_{k+1} - \hat{\mtx{x}}_{k+1} &= \mtx{A}\mtx{x}_k + \mtx{B}\mtx{u}_k -
    (\mtx{A}\hat{\mtx{x}}_k + \mtx{B}\mtx{u}_k +
     \mtx{L}\mtx{C}\mtx{E}_k) \nonumber \\
  \mtx{E}_{k+1} &= \mtx{A}\mtx{x}_k + \mtx{B}\mtx{u}_k -
    (\mtx{A}\hat{\mtx{x}}_k + \mtx{B}\mtx{u}_k + \mtx{L}\mtx{C}\mtx{E}_k)
    \nonumber \\
  \mtx{E}_{k+1} &= \mtx{A}\mtx{x}_k + \mtx{B}\mtx{u}_k -
    \mtx{A}\hat{\mtx{x}}_k - \mtx{B}\mtx{u}_k - \mtx{L}\mtx{C}\mtx{E}_k
    \nonumber \\
  \mtx{E}_{k+1} &= \mtx{A}\mtx{x}_k - \mtx{A}\hat{\mtx{x}}_k -
    \mtx{L}\mtx{C}\mtx{E}_k \nonumber \\
  \mtx{E}_{k+1} &= \mtx{A}(\mtx{x}_k - \hat{\mtx{x}}_k) -
    \mtx{L}\mtx{C}\mtx{E}_k \nonumber \\
  \mtx{E}_{k+1} &= \mtx{A}\mtx{E}_k - \mtx{L}\mtx{C}\mtx{E}_k \nonumber \\
  \mtx{E}_{k+1} &= (\mtx{A} - \mtx{L}\mtx{C})\mtx{E}_k \label{eq:obsv_eig_calc}
\end{align}

For equation \eqref{eq:obsv_eig_calc} to have a bounded output, the eigenvalues
of $\mtx{A} - \mtx{L}\mtx{C}$ must be within the unit circle. These eigenvalues
represent how fast the estimator converges to the true \gls{state} of the given
\gls{model}. A fast estimator converges quickly while a slow estimator avoids
amplifying noise in the measurements used to produce a \gls{state} estimate.

As stated before, the controller and estimator are dual problems. Controller
gains can be found assuming perfect estimator (i.e., perfect knowledge of all
\glspl{state}). Estimator gains can be found assuming an accurate \gls{model}
and a controller with perfect \gls{tracking}.

The effect of noise can be seen if it is modeled
\glslink{stochastic process}{stochastically} as

\begin{equation*}
  \hat{\mtx{x}}_{k+1} = \mtx{A}\hat{\mtx{x}}_k + \mtx{B}\mtx{u}_k +
    \mtx{L} ((\mtx{y}_k + \mtx{\nu}_k) - \hat{\mtx{y}}_k) \\
\end{equation*}

where $\mtx{\nu}_k$ is the measurement noise. Rearranging this equation yields

\begin{align*}
  \hat{\mtx{x}}_{k+1} &= \mtx{A}\hat{\mtx{x}}_k + \mtx{B}\mtx{u}_k +
    \mtx{L} (\mtx{y}_k - \hat{\mtx{y}}_k + \mtx{\nu}_k) \\
  \hat{\mtx{x}}_{k+1} &= \mtx{A}\hat{\mtx{x}}_k + \mtx{B}\mtx{u}_k +
    \mtx{L} (\mtx{y}_k - \hat{\mtx{y}}_k) + \mtx{L}\mtx{\nu}_k
\end{align*}

As $\mtx{L}$ increases, the measurement noise is amplified.
